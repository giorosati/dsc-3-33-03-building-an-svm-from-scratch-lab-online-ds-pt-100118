{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an SVM from Scratch - My Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on turotial by sentdex on Mahine Learning with Python.\n",
    "\n",
    "Lesson here: https://pythonprogramming.net/q-learning-reinforcement-learning-python-tutorial/\n",
    "\n",
    "Youtube videos here:\n",
    "\n",
    "https://www.youtube.com/watch?v=AbVtcUBlBok&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&index=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {-1:np.array([[1,7],[2,8],[3,8]]),\n",
    "             1:np.array([[5,1],[6,-1],[7,3]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Support_Vector_Machine:\n",
    "    def __init__(self, visualization=True):\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r', -1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "    \n",
    "    #train\n",
    "    def fit(self, data):\n",
    "        #need to figure out w and b\n",
    "        self.data = data\n",
    "#         { ||w|| : [w,b]}  \n",
    "#         create a dictionary where the key is the magnitude of w,\n",
    "#         and the value for each key is the w and b values.\n",
    "        \n",
    "    # for magnitude, the sign doesn't matter, but for each w the sign matters\n",
    "        transforms = [[1,1], [1,-1], [-1,1], [-1,-1]]  #have to try out each sign of the w values\n",
    "        \n",
    "        all_data = [] # get all the values for each feature, store in one list\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset:\n",
    "                    all_data.append(feature)\n",
    "        \n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None  #clear the all_data list\n",
    "        \n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                     self.max_feature_value * 0.01,\n",
    "                     self.max_feature_value * 0.001]  #point of \"expense\"\n",
    "        \n",
    "        # support vectors will be  yi(xi * w + b) = 1\n",
    "        # when it gets really close to 1 it has been \"optimized\", although some cannot be optimized\n",
    "        \n",
    "        # extremely \"expensive\" to try out different values for b\n",
    "        b_range_multiple = 5\n",
    "        \n",
    "        # \n",
    "        b_multiple = 5\n",
    "        \n",
    "        latest_optimum = self.max_feature_value * 10   #this is to save a lot of processing\n",
    "        \n",
    "        #stepping process\n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optimum, latest_optimum])\n",
    "            \n",
    "            # we can only do this because the problem is convex\n",
    "            optimized = False\n",
    "            \n",
    "            while not optimized:\n",
    "                # this could instead have a range of values like used for step_sizee, but takes\n",
    "                # alot of processing\n",
    "                for b in np.arange(-1 * (self.max_feature_value * b_range_multiple),\n",
    "                                   self.max_feature_value * b_range_multiple, step * b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w * transformation\n",
    "                        found_option = True\n",
    "                        # weakest link, SMO attempts to address this\n",
    "                        # yi(xi*w+b) >=1  this is the goal each time\n",
    "                        #\n",
    "                        # #### could make a break here to save processing\n",
    "                        for i in self.data:\n",
    "                            for xi in self.data[i]:  #could call xi \"y\" instead\n",
    "                                yi=i\n",
    "                                if not yi * (np.dot(w_t, xi) + b) >= 1:\n",
    "                                    found_option = False\n",
    "                                    \n",
    "                        if found_option:\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]\n",
    "                if w[0] < 0:\n",
    "                    optimized = True\n",
    "                    print('Optimized a step')\n",
    "                else:\n",
    "                    # w = [5,5]\n",
    "                    # step = 1\n",
    "                    # w - step = [4,4]\n",
    "                    w = w - step\n",
    "                                \n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "            \n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "            latest_optimum = opt_choice[0][0]\n",
    "        \n",
    "        \n",
    "    #predict\n",
    "    def predict(self, features):\n",
    "        #sign of (x*w+b) determines the classification\n",
    "        classification = np.sign(np.dot(np.array(features), self.w) + self.b)\n",
    "        return classification\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll program a simple Support Vector Machine from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:\n",
    "- Build a simple linear max-margin classifier from scratch\n",
    "- Build a simple soft-margin classifier from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines can be used on problem cases where we have an $n$-dimensional feature space. For teaching purposes, however, we use a 2-dimensional feature space so you can see what exactly is going on when using support vector machines.\n",
    "\n",
    "Scikit-learn has excellent data sets generator. one of them is `make_blobs`. Below, you can find the code to create two blobs using the `make_blobs` function. We will use this data to build our own SVM from scratch! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAE/CAYAAADfZK+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XeYVEXWwOHf6Z4OkxkykhEEA0EE\nTCAmgglzXnXdXVFXXTOKLKZVP/OKu+YcMGJWVlbCmlAkSEYRQSRnZpiZzre+P24zTA5MT3fP9Hmf\nh8fp27fvPY1wqLpVdUqMMSilVCpxJDoApZSKN018SqmUo4lPKZVyNPEppVKOJj6lVMrRxKeUSjma\n+FTSEpH7ReT5at7fKCKDa3GdkSKyIrbRqcZME5+qFREpLPXLEhFfqdcXJjo+peoiLdEBqMbBGJO1\n+2cR+Q34izFmauIiUmrvaYtP1ZuIZIuIX0Ryoq/vEZGAiKRHXz8sIvdHf24uIm+IyBYRWSUiY0RE\nqrl8poi8JyK7RGS2iBxYRQzpIvKEiGwQkbUi8pCIuMqdc5eIbBeRlSJydqnjp4rIT9F7rBGRv9X7\nN0UlNU18qt6MMbuAhcCQ6KGjgLXAYaVefxn9+WnABXQFhgFXAhdUc/kzgVeA5sBHwPsi4qzkvLuA\nPkBv4BDgaGBMqfe7AG6gLTAaeEVEukbfexG42BiTDfQDvq7hK6tGThOfipUvgaEi4gF6AE9FX2dj\nJ6Rvo++dCdxijCk0xqwAHgMuqua6M40xHxtjQsD9QEugfyXnXQjcYYzZaozZBNxT7rph4C5jTDDa\nRZ8KnFXqvQNFJNsYs80Y8+Pe/RaoxkITn4qVL7FbWYcCc4DpwFDgSGCRMaYAu7XlAH4v9bnVQPtq\nrrtm9w/GmDCwHtin9AnRrnLb6LWquu4WY4y/3Pu7r3MadkL+XUSmi8iA6r6oavw08alY+RroC5yE\nnQTnA72A4ezp5m4ELKBTqc91AtZVc92Ou3+IdnH3wU5+JYxdYmgj0Lma67YUEW+599dHP/+dMeZk\noA3wX+DNauJRTYAmPhUTxph8YAn2M7svjTEWdsvvL0QTnzEmAHwA3CcimSKyL3At8Ho1lz5CRE6O\nDlSMAbYB8yo5703gDhFpISKtgXHlrusCxouIW0SOxX6++F40jvOiAzMhYBcQ2cvfBtVIaOJTsfQl\nIOxJTF8CmcA3pc65PPrf1djd4eeBidVc8z3gT8AO7O7omcaYyhLT7cBS7OQ7H/gWeLDU+79hP8vb\niD2YcakxZmX0vT9F48kHLgYuqf5rqsZOtBCpUirVaItPKZVyNPEppVKOJj6lVMrRxKeUSjma+JRS\nKSch1VlatmxpunTpkohbK6WasLlz5241xrSq6byEJL4uXbowZ86cRNxaKdWEicjqms/Srq5SKgVp\n4lNKpRxNfEqplKOJTymVcjTxKaVSjiY+pVTK0cSnlEo5KbW9pLEKITANjA88xyLO1okOSSmVACmT\n+Ez4N8y2s4EQGAPcC3n/QjxHJzgypVS8pUxX1xTcA6YATDHgAwKY/FuxK6QrpVJJyiQ+QguActWm\nrSKwtickHKVU4qRO4kvrXvGYuMCRG/9YlFIJlTKJT3JuA8nA3mzLAXghexz25l1KqVSSMoMb4uoN\nLSdjfB+AKUa8JyGuAxIdllIqAVIm8QGIcx8k66oGubYxIYhsAEdLxJHRIPdQSsVGynR1G5Lxz8Bs\nPgKz9RTM5sOwCp9NdEhKqWpo4qsnY23H7PwbmHzsaTJ+KHwCE5iV6NCUUlXQxFcLJrIeK/9WrC0n\nYuX/HRPZuOe9gvuAQLlP+DD+T+Mao1Kq9lLqGd/eMFYBZuvp9uRnIuD7DROYDi2/gPDP4P+8kk85\ndZqMUklME19N/J/Za3uJRA+EwSoG/xRMaDEQquRDDiT93PjFqJSqE+3q1sBEtgLBckeDYLaDIxtw\nlnvPAVnXIWkd4xOgUqrONPHVQLzHAO5yR9PAPRRJP9te/VHCAY48JPPiOEaolKorTXw1ENdBkPU3\nwAOSZf83+ybE1QNJ64A0fx1cg8DRAjzHIy0mIeJJdNhKqWqk5DM+YyKY4nfA/xE4miOZlyPuvlWe\n78j6CybjHIisBmdXxJFV8p64eiMtXo9H2EqpGEnNxFcwHnyfYc+7AxP4Bpq/gLgHVvkZceSAo3ec\nIlRKNaSU6+oaazv4PmZ30rP5MbsmJCokpVScpVziw9oOUklD19oU/1iUUgmReonP2RUkvdxBN3iH\nJSQcpVT8pVziE3EizZ4CyQHJBLzg6oNkXp3o0JRScZKSgxvi7getZ0JoEThykcqqMyulmqyUTHwA\nIm5wH5LoMJRSCZByXV2llNLEp5RKOZr4lFIpRxOfUirl1DvxiUhHEZkhIstEZImIXBuLwJRSqqHE\nYlQ3DNxojJknItnAXBH5whizNAbXVkqpmKt3i88Ys8EYMy/68y5gGdC+vtdNJsZYWIVPYW06DGtT\nf6z88Rjjq/mDSqmkFNNnfCLSBTgYaFJbjJmiF6HwSbvqsikE3yTMjhsSHVatGasAE5iJCf+e6FCU\nSgoxm8AsIlnAe8B1xpiCSt4fDYwG6NSpU6xuGx9FL1F2J7UIBKdhRXbhcGYnKqpasYo/gILb7UrR\nJoTxDkdyH0SkfMl8pVJHTFp8IuLCTnoTjTHvV3aOMeZZY8wAY8yAVq1axeK28WMKKz8e+iG+cdSR\niWy1kx6B6HcIQGAq+CcnOjSlEioWo7oCvAAsM8Y8Wv+QklClGwc5EJMf91DqJDS73J4ggPFh/F8k\nJh6lkkQsWnxHAhcBx4rI/OivE2Nw3eSReTUVd1NLA/fhiYim9hxtAKvcwTRI65CIaJRKGvV+xmeM\n+QaQGMTSIIwJAGIXJdhL4h2BCZ4Jvo9KnpWR83fE2a6OsViIxHHOuOtgSOsBoZ+wn1E6QdKRjIvi\nF4NSSajJVmcxVj5m500Q/AZwYLwnI7l379UOaCKC5N6DyforhFeD6wDEkVv7WILzMfm3QmQlxtEG\nsm/Hkd7whU9FBJq/iil6FQIzIK07kjm6zglbqaZGjDFxv+mAAQPMnDlzGvQe1vbLIDgTCEWPeCDj\nPBw54xr0vuUZKx+zZSiY4lJHvUiL9xBXj7jGolRTJyJzjTEDajqvSa7VNSYQbemFSh0NgO+DKs5v\nwOQfmAYVLh/C+D9suHsqparVJBOf/cixkq9WboTTBL7C2nIMZlMvrC0nYII/NkAsVf0WN9HfeqUa\ngSb5t0/EDd6TgNIDGulQ6qG+Cf+G2XE1RNYBBiK/YnZcam8/GUue46DCgIYLST+90tNNZBvG9ykm\nMAtjyo/IKqVioUkmPgA8Q9nz9RzgPQHJvKLkbeP7GLu+QmkGYjzHzfgngwlTMvDtaI3kPYmkdatw\nruX7FLPlaEzBeMzOyzHbTsNYVUyeVkrttSaZ+Ez4V8gfC/ijRyx7tYK1tdRZVc3AqX5mjjFhrIL/\nw9rUF2vjgVg7b8RYRZWfG1oIBfdG44g+6LMKMM5eWEVvY20ZgbX5WKzCp7EiBZB/G/YqiyJ7MCS8\nElP0XK2/t1Kqdppm4vN9RsXWHBDY05qT9FFUnM0jNe6vawr/BcVvgvEBIfBPweSPqSKOTym7xhcQ\ngV33wq77ILIKrLV2AYSCv1ey0XkQAl9VG49Squ6aZOJD3FRouYkAewY3JK0zkvckODsCDkjrgeS9\ngjjyqr928dvsaUmCnZxmYIy/4rmSQcUVHw4Ifg2ULmvlh8B0MIGK5+rWl0rFXKNPfMbajlVwL9bW\nU7B23oIJr7FbcxVaT07wDi9zRDyDcbSahqPtTzhafgau/TBWMbEi6WeWG0l2YA+4RCo5OwLeUUB6\n9HWavcoi668xi0cpZWvUKzeMCWK2nQWRTUAIwr9gAtMgexyk7QfhX+1WlOtAJOdOxNFsz2dDv9ir\nKcJLQFqBsy2ElwIG4z4SafYI4sipeNOMc6Nlqna38NzgGYqIt8KpktYR8l7F7LoPwqvA1RfJGY8p\negp8nwDB6JlOcA1Acu8D79EY/+fg3AfJuBBx7hPb3zSlVONOfAT+B9YO9kxUtuyBgYJx7HnG5wHv\nWYjrgJKPGePHbL8AdldXMZsgvGnPdYMzMfljkbwnKtxSsq6xu7XFb9n38A5Hcu6uMkRx90VavF32\nYPY4TGQzBKP1WtN6Is0etZeYeUcg3hF1+E1QStVV40581jYw5buN5V8HYNffscILkJy7EEmDwNdU\nOvhRIgSB6RgTwa5u4iwpLiCShuSMhZyxex22OLKQ5i/YcwZNGHG23utrKaXqrnE/43MPppL1YJXz\nfYIpeiX6ojafcWC2X4rZ1BuzqR9WwUMxn1Asjuaa9JRKgEad+CStI+T8HfCCZAFukJZVnO0H3yT7\nR88QKo62luYFR7ZdyBPL/mzx65jiVzGRjZjgHJ1YrFQj1qgTH4Aj41yk9Uwk7yWk9VdIi4kgzas4\nOQsAkXSk+euQtr99XFqC50RwtLQ/m34WWIWU7Tb7YNfjmC3DMDtGYzYfgeX7pEG/m1KqYTTqZ3zG\nKsQU3AH+Kfb0lfQLkewbkNbfYradA+Gf2DPw4UUyLy/5rLh6IS0/whhjDyqUvm5kM8b3TiV3LALM\nnvl2+bdhPEcijioSrVIqKTXqFp/Jv9lOegTtJV7Fr2GKnkbEiTR/DdLPA0crcHZHmj2AeI+vcA0R\nwfJ9jrV5CNbGXlhbzwQrH1z9KD3h2e4al3826IDA9w33/UwAY+1ssOsrlaoabeIzVjEEvmTPXDiw\nn8VNBEAcGThyx+No/S2OVpMR7wmVXye4APLHgLUJsCC8GLP9Qmj2KHhHYD8/bA6uQ6i4jteHMbGb\n8FwSk7GwCv4Ps2kAZvORWFtPxoR/i/l9lEpVjTbxxYrdpS29VMwAYSS0CMl9BGn2ILgPBsml0tFg\n/6dlr2cMJrza3tpxb2Mqfis6TzBAycTs7Zc2bMFUpVJIo33GJ44MjGcIBL5lT6vPa3dva8lE1oP/\nf1Q+vcVgdj0MvtejBQmqqNoSXrHnE+GVmB2XQWQLYGE8Q5Bmj9V9nw/fu5Rdy2vA7IDwcnD1rNu1\nlFIVNOoWn+Q+Yhf6JA270Oj5tV7baozBbL8YTGUtMyfGdTAUvxpNelB5cnSAq/+e6+0YDZG12MvZ\nghD4BlP47zp/LyS94jFjYRBM8bt2N9g/NTrBWilVV422xQfRFRB5E0q6gOVHZ6sVXhatz1c+oWUg\nzSeCKcJU+e+C2y4+IF4k5xb7kLU+uma49PUC4PsUsm+sfVyAZF6G2bmEPa0+l732eOfVmMgmwIcp\nfhs8R0CzJ+r2vZVSyd/iM1YhVsF9WFuGYW2/pNJ9MUQkdn/5XQchrv3A2R4cGVWfl3Mn0moG4mwf\nDSKTSluFddiGcjfxHgO594Gzi/1s0XsKeAZDZD17kmGx3c0PLazz9ZVKdUmd+Ozu6CVQ/AZEVkPw\nO8z2P2JCS+t/8bT9wdGaMr8Fko5kXmL/KE6k2eNU+mxP0hBX7zIVWcTRLFrEtHSVFi+SddVehSfO\ndvbG5aYI/J9A0ZOUHcGOCv+yV9dXKpUldeIjvAwiKyg/ZcUUvVDvS4sI0vxVcB8OOO0pK1ljkFIV\nmMU9ENxDKn7YWOBoW/GauQ9A1uV2S83VG2n2zzLXqy1jFWJ2/AmsddjFFEJVnQmuPnW+vlKpLrmf\n8Vk7qbim1thVWWJAnG2R5i9Vf072LZjtc+3WFyHAA9nXIZV0g0XcdgtvL1t5JQJfUdPeH+CC9DPs\nbrlSqk6SO/G5+1PhuZmkR/fLiA9x9YCWn2N8H4C1E/GOQNwHN/BNa5r+4obsMTgyL27YOJRqopI6\n8Yl4Ie9ZzI6rsJelhcF7KnhPi28czjZI1hU1nwgY44PgPHA0h7Reezfo4hkC4o1OpSlfCssFzvZI\nxoV1v65SCkjyxAfR52ytZ0LkN3C0qHkzoL1gwivs54aRTYj3ZEg/raTwaK2vYQKYwueh6Gl7qouJ\ngKsX5L1Uabe4OiJuaP42puAuCP1orzd2tAJrO3gGI1l/RaS6slpKqeokfeIDu+pxQ+02ZkJLMdvO\nx14eZmGCcyH0A5J7f82fNRYQhsjvmK3nA7tL2UeXwIWW2FtPeo619+Vwtqh1XJLWCWle/0EcpVRF\njSLxNSRT+C/KbPiND3yfYrJuqLY6slX4PBQ9Ee2Ouim75eRuQQh8gQl+AwUW5D2OeI6O9VdQStVR\nck9niYfIGioOoLij1VoqZ/xToPBf9hy73RWaqz7bLpmFH7NzjC4zUyoJaOLzHAtUMoqaVnUxAFP8\nJmWLCNSS8VebUJVS8ZHyiU8yLwfX/nZhAMmyp8s0e8weYKiSq5r3wJ6Dl1XJYQFH7Z/zKaUaRso/\n4xNHJjR/295M3NoGrkPsY9V9JvMSTPAH9rT6nPbyN/eRIAZJPw/EaRc0NSHsvTu8kHVD3UtUKaVi\nLiaJT0RGAhOwl1k8b4ypeUg0iYgIuA6s/fmewZicu6Hwn/YUE/dhSO4/EGebsie2+AzjexesAiT9\nZMR9SIwjV0rtjXonPrEnlD0BDAPWArNF5GNjTAwqCSQvR8apkHFqtedIWgck+/o4RaSUqq1YPOMb\nBKwwxqw0xgSBt4DqM0KKMMZgTFUFBpRSiRKLxNceWFPq9drosZRmFb2K2TwAs+kgrK2nY8IrEx2S\nUioqFomvssWoFSpyishoEZkjInO2bNkSg9smL+OfAbseAbMLMBBeitl+EcaEEx2aUorYJL61QMdS\nrzsA68ufZIx51hgzwBgzoFWrVjG4bd0Z/xSsrWdibTkBq/CFBptMXHGeX3QSc6hi9WilVPzFYlR3\nNtBDRLoC64DzgAticN2Ysoo/gYK/U5KQCidgIquR3Ltjf7MqCwik/OwhpZJCvVt8xu6/XQ1MAZYB\n7xhjltT3ujFX9C/KtsL84HvfLiMVY5JxMWVL0DvAkQeuvjG/l1Kq7mLSBDHGTAYmx+Jae3V/qxgC\n04EgeI6pvHSV2VXZJ+0iA5Vt51gP4jkck3sv7Ho4Os9vIJJ7b51LXZVEaYLg/xwTWoS4+oB3RA0r\nS5RS1Wn0fS8T/hWz7TwgDMYAd0Hz5xD3oLInekaAbxJ79u9wQFo3xNG8QeJypJ8C6afU+zrGhDDb\nLohuKuTDkA7Fr0HzN+xyXUqpOmv0a3VNwZ1gCqKVUooBH2bnzSV77e4m2TeDewB2QQIvODshzZ6I\nf8B1FZge3XBpd5fcB+HlEPhfAoNSqnFr/E2G0CIqzJ6xttiJUPYUChBHJtL8ZUxko10lxdm5cWzE\nHf4lWtaqFOOPtgCPT0hISjV2jb7Fh7NzxWOSCVJ5uXdxtkXSujSOpAf29pHlv4t4dVtJpeqh0Sc+\nyfk7kI7deHUAXsget9cDCUnHPdje+1cyALf9X/eR4D4i0ZEp1Wg1+q6uuAdCy48wvvfABJD0UYjr\noESHFTMiDmj2JITmQGiZXTvQNaDxtFiVSkKNPvEBdtc1+8ZEh9FgRATcA+1fSql6ayL9QaWUqj1N\nfEqplKOJTymVcjTxKaVSjiY+pVTK0cSnlEo5TWI6S6IZE4DgLMAD7gFIlfX4lFLJQBNfPZnQUsz2\nS7D3zjUgOdDiLcTZLtGhKVWjXTsKWfPTOjr03Iec5tmJDiduNPHVgzEGs/N6MPmlDvowBXciec8k\nLjClauGdhz/mldvfIs2dRjgY5uI7z+HcMaclOqy40Gd89WGKIPJ7uYMWBH9ISDhK1daK+at49Y63\nCfpDFBf4CPpDvHbXu6z4cVWiQ4sLTXz1Iel2pZTyHG3iH4tSdTD7P/MJB8vu+hcKhpk1eV6CIoov\nTXz1IOKErGuxq8OAvdOmF8m+JYFRKVWzvDa5uLyuMsfcXhd5bZolKKL40sRXT47MPyJ5/7JL23tH\nIc1fQ7zHJDospao19JzDSc9Kx5lmz0BwpjnxZno5+tzUKHemgxt1ZKxCsDaBs2PJhj/iOQrxHJXg\nyJSqvfSsdJ6a9yAT75nEkpk/c8Bh+3Hh+LPIyI7txlvJKqkTnzEhTPFE8H0CzlZI5pWIO3FbNFqF\nT0PhE9F9cx2YnPtxpA9PWDxK1UeLdnn87YnLEh1GQiR34su/GfzTAb+9iVpgJjR/GXH3j38swR+g\n6CkgsGeLj/wbMe7piLNV3ONRSu29pH3GZyKbwD8N8Jc66scU/jsx8fgm25v8lCYOCHyVkHiUUnsv\naRMf1naobN/YyMb4xwLgyKNiA9kBjpxERKNUgyre5WPlwtX4ivw1n9wIJW9XN60H4AaKSh30gPeE\nhIQjGedgil8CE8bu66aBZINnaELiqYyJbMAUvwGRDYh3OHiG6d4cqs4mPfoJL41/C2eaAytiuGrC\npZzw5+MSHVZMJW2LTyQNyXsKJNfeLhIPuAciWaMTE4+zHdL8HXAPBUcHSD8FaTGpZGQ30Ux4NWbr\nSVD0Ivg/xuSPsTdbV6oOfp7zKy/f/hZBXxDfLj+B4gD//tuLrF2+vkHuZ4zhi9e+5NrB47j5uDuZ\n9dncBrlPecnb4gN7EKP1TAgtAUdzJK1TYuNx7Yc0fzahMVTFFD4R3Xjcih4oBt97mKy/Ik5dSaJq\n57uPZxP0h8ocM5bFrM/m0WG/fWJ+v1fveodJj3yCvygAwLJZv3DdM5dz/IUNOz0saVt8u4m4EHe/\nhCe9pBf+hZKkt5u4IbI2IeGoxim3ZQ4uT9kVHU5XGjktY1+5JRKO8O7DH5ckPYBAcZBXbn875vcq\nL+kTn6olzxDsZ6KlmDCk9UxIOKpxOu7CIbi9LhwO+9mww+nAm+Fh8BmHxvxewUCIUCBc4XjB1l0x\nv1d5mviaCMkcDWldos9DMwAP5PwDcWQlODLVmOS0yOaJH+7nqHOOoH2Pthz/h6N4cs4DpGdWUoyj\nntIzvXTr27nMAJzT5WTAyH4xv1d5Yoyp+awYGzBggJkzZ07c79vUGWPZlaCtreA+TCdWq6S39pcN\n3DLsbnZtL8RYhvY92nH/f/9Os1a5e3U9EZlrjBlQ03lJPbih6kbEAZ7DEx2GUrXWoUc7Xlv5BCsX\nrMblSaPT/h3iMgVLE59SKqEcDgfdD+4a33vG9W5KKZUENPEppVJOvRKfiDwkIj+JyEIR+UBEUqN8\nq1KqUatvi+8L4CBjTB9gOTC2/iEppVTDqtfghjHmv6Vefg+cVb9wlFKJkr+1gLcf/Iil3/3MgUf0\n4pybR5HbsmlWH4rlqO6fgCrXmojIaGA0QKdOuvxMqWTiK/Jz5SFj2LEpn3AwzPLZvzLjrW94cdkE\nvBmeRIcXczV2dUVkqogsruTXqaXOGQeEgYlVXccY86wxZoAxZkCrVomZWGv8M7C2nY+1dRRW0Wv2\nhF+lFF+9+x27theWbDkZCobZtb2Qryd9n+DIGkaNLT5jzPHVvS8ilwAnA8eZRCwDqSXL9x/Iv4WS\nis67HsKEVyK5dyQ0LqUAtm/cwYvj3uTH6Yvo1Ks9f77vwrjObdu6bnuFqixBf4gta7fFLYZ4qu+o\n7kjgFmCUMaY4NiE1kMLHKV/GHt+7GCu5w1ZNXzgU5prDb2Pqa1+xefVW5kxZwPVHjWfDqk1xi+GQ\nYX1wecq2g1yeNA4Z1iduMcRTfUd1/w1kA1+IyHwReToGMTUMs7OK4774xqFUOXO/WMiu7YVEwpGS\nY+FgmM+e+SJuMfQa1IMzbzgFt9dFZm4GLo+Ls248hZ4Du8cthniq76hu4/ld8QwH3yRgd3Ne7L1x\nnS0SGZVSFO4o2rNzX1Q4FCF/a0Fc47j07vMYdeUIVi9ZQ+cDO9KiXV5c7x9PKbNWV7JvxoRXQGih\nvTua5CF5TyQ6LKU4ZHgfrEjZgTZvpodjzhvc4PcOh8L8OG0RoUCY/sP60KJdXpNOeLulTuJzZCEt\nJmLCa+zubVoP3YhHJYVmrXL5+9s3cP/FjxMJW1hhi3PGnEr/4xv2+dqGVZu4bvB4/KV2Untw6h30\nHLBvg943GWg9PqWSRDgUZsPKTbTYpzkZ2ekNfr+xJ9zLvC8WYFl7ckD77m156efHG22joLb1+LRI\ngVJJIs2VRsee7eOS9AAWf/tTmaQHsPG3zfgKm+ZeuqVp4lMqRbXuWHFgz5vpxZORHFumNiRNfEql\nqCseuQRPhhuJbizkyfDw5/+7AKfTmeDIGl7KDG4opcoaOPJgHvv6Hj5+agpBf4gT/nQsfY8+MNFh\nxYUObiilmgwd3FBKqSpoV1epOIhEIsz8cDY/zlhM5wM6MOyioTEfvQ0FQ0x7/Wvm/HcB3fp04uTL\nh5PTIjum92gqtKurVAMzxnDH6Q/y47TF+Iv8eDLcNGuVyzPzHyIzNzNm97j5+Lv4adYKAsUB3F4X\nWXlZPLfoEXKap07y066uUkli+Zxf+XHaopIVEoHiIDs35zP5+Wkxu8eSmT/z8w920gO7pFThjkIm\nPxe7ezQl2tVVqoH9vmwdUHYlRMAXZMWPq+p97a3rtvHZs1NZ8L8lRMJl1/sG/SFWL1lT73vUZNXi\n3/nPC9OIhCIM/+MxjWLJmyY+ldK+fn8W7/3zE8LBCKP+OoJhFw+N+XKtnoO6Y0UiZY55Mzz0O+ag\nGj+7ec1Wpr3+FaFgmKHnHEHn/TuUvLf2lw1cNfAWQv4QoWjl5DL3yPRwyPC+9f8C1Zj9+Y/cddbD\nhPwhDDDl5Rnc8NwVHHv+kAa9b31p4qsDE9mCyb8VgjNBMiHzciTzL412XWOqm/z8VJ687uWS7uG/\nrl7DptVbuOj2s2N6n0692nPq1SP5+IkpAIjTQbc+nTnuD0dV+7ml3/3MLcP/QSQUwbIs3nnwI8a8\ncjVHnXU4AK/d9Q7+Qn+FZWfeDA8I9B6yP8ecd2RMv0t5T1z7EoHiYMnrQHGQJ697mWPOG5zUfy90\ncKMOrK2jILwCe3sRgHQk904k/fREhqX20nkdL2fbuu1ljnkzPXyU/yoOR+wff69cuJol3/5E+x7t\n6HfsQTXe48oBY1gxr2x3OLdVDu9seA6Hw8HovjeyatHvZd5Pz/Jy9k2jGHTCwew3YN8GTz4npp9P\nKFC2tSkifOabiMvtatB7V6a2gxva4qslE14N4d/Yk/QAfJiiVzXxNVKFOworHAv6gkTCERzu2Ce+\nbn06061P51qfv/bn9RWOFe6PzirDAAAeaElEQVQoxF8UICM7nf7H92Htz+vLdHMty+KsG04mPSs+\nhQ72O2Rfln73M6XbTx32a5eQpFcXOqpbb0m7v5KqwcARB+N07VmX6nAIPQ/tkTR/afft26XCsbw2\nzUjP8gJwwbgzaN25FenZXrxZHtxeF9c9c3nckh7A9c9eTlZeFunZ6aRne0nPTmfMK1fH7f57S7u6\ndWB3dX8Bdj+oToecO3FkaIuvMdq5JZ9bR9zD2uXrERFa7JPHA/+9nTadE7P9aXkrF67m+qPGY0Us\nLMsgwJ0fjGFAqQGLSDjCvKkL2bEpn/7D+tByn+Zxj9NfHOCHyfOIhC0GnXgwmTkZcY9ht9p2dTXx\n1YEObjRNa35eRzgUocuBHZPu/+WuHYV88/4sQoEwR5w2MCGJrTq/LVnDlrXbOOCwHiWTsYsKiln6\n3XJa7pNH196179rHgiY+pZLY1Ilf8dK4N8nfWsDBx/bm2qdHJ11Sq04wEOL2Ux9g8TfLcKY5iYQi\n3PLqNTjTnNx34WP2sbBFr0O7c99nt+H2xqfGnyY+pZLUnP8u4M4zHiqZRuNMc9CuWxteXDYh6Vqc\nVXl/wme8eNsbBHx7prJ40t0glJne4kl3c9EdZ3PumNPiEpcuWVMqSb0/4dOSpAcQCVtsW7+DX+at\nTGBUdfPNB7PKJD2gpKBpaQFfkG8//CFeYdWaJj6l4iwcqLjKArH30q2L1cvW8rcjxjHSfR5/6PZX\nZn40O0YR1qz9vm1xOMumDyti7xBXmsMh7LNv27jFVVua+JSKs1OuHIEn01PyWkTIyMmg58Dar3EN\n+AJcP2Q8P81aTiQcYdNvW7jvwsfi1mo895bT8KS7S5KfJ8NN/+P7cNgph+DJsL+bw+nAneHh/NvO\niEtMdaETmJWKs8FnHMr6lZuYeM8kAkUB9u3XldveuLZOe13MmbKASChSZuJw0B9i8vNTufbJ0Q0Q\ndVkd9tuHJ+c+yDsPfcSGlZsYcsZhnHjZcYgI/3lhOl9N+o42nVtxzs2j6NizfYPHU1ea+JSKMxHh\n3JtP5ewbTyEcDFc64hkOhXnvn58y7Y2vyW2Zw4XjzixT1MCyTPmCL2CoUKGlIXXo0Y4bnr2iwvGT\nLx/GyZcPi1sce0MTn1IJ4nA4qpzmcf9Fj/PdJ3MJRgcQln2/nLs/upX+x/UGYMCIvhVGgN3pLk74\n83ENG3QToc/4lEoyOzbtZOZHc0qSHthTRF6/+92S1+mZXh6ecSdde3cCIK9NLjc8dwX7H9oj7vE2\nRtriUyrJFGwvxJnmIBQoe3zHpvwyr7v368qzCx7BsqwGqSbTlOnvllJJpmPPfSqsd3V7XQw994hK\nz29qSc+yLJZ+9zPzpi4kGAg1yD20xadUknE4HPzjk1sZd9J9+IsCRMIR+h17EBeMjV8xjPW/bmTq\na18RiUQ49vzBdD6gY1zuu2NzPjcMvZ1t67YjDsHhcPDAF+PZ75DYlrPXJWtKJalIJMJvi9eQnZdJ\n607xqxgzf8Zi/n7K/YRDYYxlcLnTGDvxWo48bVCD3/v//jCBL9/5jkh4z2Tutl1a8+qv/67Vcj5d\nsqZUI+d0Otm3b5e4Jj2Af139PIHigF3yPmIR8AV5/KrniUcjac5/F5RJegDbNmxn5+b8Kj6xd7Sr\nq1ScGGP4atL3THl5Bpm5GZx53Un0GpR8o7Drf91U4diOjTuIhCOkuRo2ZbRq35yCrbvKHHM4HGTm\nxrbGX0xafCJyk4gYEWkZi+sp1RS9fPtbPPynJ5j9nx/58u1vuemYO5k3dWGiw6qgsvL47bq1bfCk\nB/Dn+/+AJ8PN7l6tN9PD2TefGvOyVvVOfCLSERgG/F7TuUqlgp1b8vny3e9Y/M2yku6hvzjApEc/\nxV9kz1Exxq5c8sLYiYkMtVLXP3M5GTnpeLO8eDM9eDM93PTiX+Ny74Ej+vHQtDsZes6RDDqxP2Ne\nuYaL74jtrncQm67uP4ExwEcxuJZSjdr0N7/mkT8/RZorDWMMHXruwyMz7qSowAeVPCPbvHZbAqKs\nXveDuzLxt6f49sMfiIQtjjh1AM1a5cb0HpZlseirZWxdt52+xxxYpgjr/of2YNyb18X0fuXVK/GJ\nyChgnTFmQWMpoKhUQyne5ePRvzxN0B8i6Lfnn61esoZ3H/mEi24/m9xWuWxZs7XkfKfLycAR/RIV\nbrWymmUy4o/HNMi1fYU+bjj6DtYt3wDY+4Zc/e8/c8Kf4rfcrsaurohMFZHFlfw6FRgH3F6bG4nI\naBGZIyJztmzZUt+4lUo6v87/rcyubWBXTPlh8o+ICLe/ewOZzTLIyEknPctL++5tGf3QRQmKNnHe\nn/AZvy9di6/Qj6/QT9Af4t9Xv8CuSrb7bCg1tviMMcdXdlxEegNdgd2tvQ7APBEZZIzZWMl1ngWe\nBXseX32CVioZtenSinCwbJFRh9NBp/3tsky9BvXgnQ3Ps/jrZaRnp9NrUPdGU2o+ln74z/ySFvFu\nae40Vvy4ioOP7R2XGPZ6cMMYs8gY09oY08UY0wVYC/SvLOkplQpad2zJ0ecdiTdaZDTN5cSb4eGC\ncWeWnOP2uOh/fB/2P7RHSiY9gK4HdcSZVjb1hINh2nVrE7cYdB6fUjF04/NXMmB4P75+/3tad2rJ\n6decmLB9eot3+fjm/VkUF/g4fNSApNkv+LxbT+d/78wkWBwkFAzjzfRw1NmH07ZL67jFoEvWlGqC\nNqzcxNWHjiUUCNkrIUQY8/LVDD378ESHBsDW9dv59KkpbFi1mSNPG8TgMw6NSbEF3V5SqUbCV+Rn\n56Z8WndqiTOt9uXnq3PnGQ8x8+PZGGvP3+/M3AwmbX4hLhORE0XX6irVCLx+zyTOav1nRve5kXPa\nXcbcLxaUvLdjcz7zpi1i6/rtdb7uslm/lEl6YO/itnVd3a/VFDXd1K9Ukps9ZT5vP/BhSaVlf3GA\nO05/kDfXPMNnz37Ba3e9i8vtIhgIcdo1J3DZA3+o9YBItz6d2b5hR5lj4hCat8uL+fdojLTFp1SC\nTH/j65IlbLs5nA4+f2Ear989iaA/RFFBMaFAiE+enMLib36q9bVHP3QRGdnpuL0uHA7Bk+7mikcu\nxu1xVfu5bz6YxcU9rubkrAsZO/IeNq1umnNutcWnVIJkN8/CmeYoszOaIKz9ZQNWpOxuaf7iAD/8\n50d6D9m/wnV2bM5nxY+r6Nhzn5KR0a4HdeKlnycwbeLXFO4oYshZh9G9X9dq41ky82fuv+hxAsV2\nC3TetEVcf9R4Xlv5RJ22vmwMNPEplSCjrhzBf56bRiRst/qcaU6yW2TRd+iBzHjzW0KlJkN7Mty0\n7lSx+NGkf37KS+PeIM3jIhwIcfxFQ7nu6dGICM3b5nH2jaNqHc9HT3xeZoMjK2JRtLOYxV//RN+j\nD6zHN00+2tVVKkE67LcPD02/g75HH0jL9s059vzBPD7zXgafeRi5rXJweex2SZrLSUZ2BsdeMLjM\n59et2MBL494g6A9RnF9M0B9i+htf88PkeXsVTygQqlhHQSiTgJsKbfEplUC9BvXg4el3Vjj+xOz7\neffhj1n41TJ6DerOuWNOrbAB0fzpixFH2cEOf1GA7z+bx6EnHVLnWE687Hhmfz6fQPGe545prjT6\nDD2gztdKdpr4lEpCOc2z+fN9F1Z7TssOLXA4y3ba3F4X7bqVXQGxdvl6wqEInQ/oUO2o8MAR/fjL\nAxfy8t/fwrfLR6f9OzB24rU1Dog0Rpr4lGqkBozoS+tOrdjw60aC/hBpLifpWemMvPRYAPK3FjD2\nhHv5fenakqksD/x3fLVLw0676gRGXTmCUCCEJ90Tr68Sd/qMTzV582cs5voh47lo36t4+qZX8BX6\nEh1StYL+IB88/hljT7iXZ25+tcoJzE6nkwnf3sMF486g91H7M+qqkTw9/yFyWmQD8PhVz7Nq4WoC\nviD+ogAbV27ivvMfq/H+DoejSSc90CVrqolb/O1P3DriHyVTNFweF70GdefRL+9OcGSVM8Zw3ZDx\n/Dp/FYHiIGluJxnZ6Ty/+J/ktWlWp2udkv2HSucJflzwapNNbLpkTSng7Qc+LEl6YI9cLp/zK2t+\nXpfAqKq2ZObPrFy4uiTmcDCCrzDAJ0//t87Xys7LqnDM5XGR5tYnXJr4VJOWX26rQrDny+3aUZSA\naGq26bctlB9+CAVCrI2Waa+Li+48G0/GnpadN8PDWTee3OQmI+8NTf2qSRt20VHRFlSpKRpuJ/sd\n0i2BUVWt91H7V9hQ25vp4bCT+tf5Wif86Tiy87KY9OgnhAJhTrliOCMubZh9NBobTXyqSTtx9PEs\nn7uSaRO/xpnmICMnnbs/vKVBSzMZY/a6unLrji35ywN/4PlbXifNnUYkFGHgyH4MPfeIvbre4NMP\nZfDph+7VZ5syHdxQKaFg+y4Ktu5in+5tY1LwsjLzZyzmn5c/w/pfN7LPvm254dkr9nqp1/aNO/jp\nhxW0796Wzgd0jHGkseMvDvDktS8x/c1vcKY5OOWK4Vx6z/kxqytYV1qIVKkYiIQjLPt+Oe50Nz36\nd6uyJbdl7TYu7XVtmS61J8PDSz9NoFWHFvEKt0FZlsXMj2Yz978L6NBzH0b88Rgev+p5vvlgFqHo\n5kGeDDdnXncyl95zfkJirG3i066uUlVYtfh3xhx/F0F/CMsytO7Ukoen30le64qba3/5zswKFVWs\niMWX78zkrBtOiVfIDeq+CyYw67O5+IsCuNPdvPPQx+RvyS9TXSZQHOTTZ75IWOKrLR3VVaoK/zjn\nUXZuLqC4wIe/0M+65Rt48toXKz23qpZgU9lJbdXi3/n+kzkl8wKDviC7tu/CilTsMVqWVeFYstHE\np1Qldu0oZMOvZXdKjYQjzJmyoNLzh55zeIV1sw6ng6HnJMfmPvW15qd1OMo9twsFwjRrk1tSRQbA\nk+5m5KXHYlkW330yh+dvfZ0vXv2SoD9Y/pIJpV1dpSrhzfTgdDkJh8pOLclrW/nqiZbtW3Df5Nt4\n7IpnWPfLRtr3aMv1z1xBy/bJ8Xxv1aLVTH5uGqFgmBGXHsP+h/ao0+d7DuxOJFS2PJUnw81Z15/M\n8rm/8s37P+BwCsMuOZpL7z2fu858mHlTF+IvCuDN9PDWAx/yxOz78WYkx4oRTXxKVcLldnHOzafy\n7sMfl3TvPBlu/vJ/VVdM6XPUAby4dEKDxrXxt828fve7rJj/G/2OOZALbjuzZG1uVWZPmc9dZz5E\nyG/X25v6+pf87cnLGH7x0bW+b5vOrTjv1tN54773sSIW4hDadWvDqVePxJPuwbIsRAQRYel3P5ck\nPbBLZW1avYUvXv2SU64YXp+vHzOa+JSqwkW3n03n/Tvw2XNT8WZ4OPOGk+k7NHGViHdszufKQ8ZQ\nXODDilisXrqWmR/O5sWfJlQ7L/HJ614qs2wvUBzkmRtfYdhFQ+v0DDIrLxOHQwgHLcQIG1ZuYvmc\nlfQesn+ZKUKrFv1O+dkigeIAv8xbWYdv27A08SlVBRFh6DlHMPScvZs8HGtTXp5B0BcsGT0OB8Ps\n3FrArM/mceRpg6r83ObVWyscK9xRRCgQwu111+reoWCIF8e9STA6bcVYhkBxkKdvfIUnfri/zLn7\nDdi3wue9mR4OOrJXre4VDzq4oVQjsW3d9pLEs5sVsdixKb/az/UcuG+Fll27fdvWOumBnSjLP+MD\n2LBqU4VjPfp345jzBuPN9JDmdpKe5aVr704cfd6Rtb5fQ9MWn1KNxOGjBvL5i9PLlJoyluGQ4X2q\n/dz1z17OdYPHEw6FS/bUuPW1a+p072atc8lpmcO2UhuSOxxC78EVd30DuOG5Kxj5p2NZ+t1yOvXa\nhwEj+yVVcQRduaFUDGzfuIMXx73JghlL6HRAB/7yfxfQtXfnmN7DGMMLt73B+499hsuTRjgU4a+P\n/ZGTLhtW42cDvgCzP59vr/094WAystPrfP+FXy1l3En3Rff5ENKzvPzru3tp3anVXnybhqFL1pSK\nk1AwxB/3+xvb1u8gEo4gAt5ML88tepQ2neuXFCKRCLM+m8eKeavo1rczh58ygILt9hzDzgd2rLAB\nUUMJ+AKsXb6BrLxMfvr+F7yZHvoP64PLnVz7ceiSNaXiZM6UBfYzsGg5KWPsZDj5+alc+o+9X7pl\nWRZjT7iXZd//gr/QjzfLy759u/DIjDvJa90zVuHXaNobX/PY5c8gDgeRUJjzxp7ORePPjtv9G4IO\nbihVT7u2F2KV6zmFgxHytxTU67pzpiwoSXoA/kI/v85fxcyP49db2vz7Fh697Gn8RQF8u3wE/SHe\nfuAjFn61NG4xNARNfErV08CR/SoUKPBkeOo9DWblgt8I+sou9fIXBVi54Ld6XbcuZn8+n/JT/YK+\nAF+/933cYmgImviUqqe8Ns0Y+/rfyMhJx5vlxe11cf6tp3Hwsb2r/Iwxhrcf/JAzWl7KCd7zufPM\nhyjYVrZMfvf+3XCnl51y4s300KN//KpH57TMwVluDXKa21XnjY+SjT7jUyoGBp9+KIee1J/1v26i\nVYcWNY6a/ueFabx296SS+n2zPp3L+FH3M+Hbe0vO6X98b/octT8Lv1pG0BfEne6m18DuHHpy3cvQ\n761DT+pPRm4G/qKgXXVFwOVJa/Ql7DXxKRUjLreLzvt3qNW5H0yYXKZoaTgU4ZcfV7Fl7baSwqUO\nh4N/fHwrc79YaI/q9ukU9/lwoUAIt8dlT2Gx7JiGX3I0LdrlxS2GhqCJT6kEsKyK08gEMOVq2Tkc\nDgaO6MfAEf3qdP0dm3by8u1vM3/GYroc2JE/3Xv+XpWw/+DxyWxdt71kxNqKWEx+birn3nIaLfdp\nXufrJYt6P+MTkWtE5GcRWSIiD8YiKKWaghU/ruKO0x/k8n438epd7+Av1cI79eqRZbZ+dKY56XJQ\np5hMBg6Hwlxz2G1MeXkG61ds5LuPZ3PN4ePYvKbimt2aLPzfkgrL5FzuNH79cVW940ykeiU+ETkG\nOBXoY4w5EHg4JlEp1citWrSa64aM57uPZ7Ny4WrefuBDbjthz/O7U64Yztk3nYI304s4hP7H9eae\nT8fG5N6zP59PwfZCIqFS8woDISY/N7XO1+o5qDuuchuQh4JhOh1Quy59sqpvV/dK4H5jTADAGLO5\n/iEp1fi98/DHBP3BkrWxQX+I5XNXsmrRarr27oyIcMmd53LxHedgjInpzm8F23ZhTNkuczgYZufm\n6osZFBUU8+9rXuCb92fhzfRw1o2jOOO6k/ni1S8p3FlEoDiIN9PDsEuOpl3XNjGLNxHqm/j2A4aI\nyL2AH7jJGDO7/mEp1bhtWbsNU+45njPNwY5N+XQtNctld/HOWBowoh9WuOy9vZkejjq7+nmF95z7\nKAv+t4RQIIy/KMDrd71LeqaHF5Y+xrTXv2bjb5sZMLwvBx9X9TSdxqLGxCciU4G2lbw1Lvr5POAw\nYCDwjoh0M5UsABaR0cBogE6dOtUnZqWS3jHnHslPs1aUGbm1IhYHHNHwS81atMtjzCtX88hfngQg\nEopw9k2j6F9NwsrfWsD8GUsIB/eUnvIXB3h/wmRG/XUko/46osHjjqcaE58x5viq3hORK4H3o4nu\nBxGxgJbAlkqu8yzwLNhFCvY6YqUagZF/PpaFXy3l6/dnlTwjG//OjXHbc2Lo2Ydz+CmHsO6XDbTu\n1JLM3Mxqz7ciVoUVGmAPlDRF9e3qfggcC/xPRPYD3EDdh46UamKcTidjX7+Wy9ZtY9v6HXTt0xm3\nZ08lk92doobcftLtdde6NFZem2b06N+Nn2f/WjJ1xZPh5qTRVbZ7GrX6PlF9EegmIouBt4BLKuvm\nKpWqWrZvQc+B3UuS3o5NOxk78h5Gus/j1GYXM/GeSRX2p0iUOz8YQ9+jD8ThdOD2ujjpsuM55+ZT\nEx1Wg9B6fErF0ZWHjGHVot9Ltao8/PWff+TEy5KnZRUKhnA4HUlVMbm2aluPT4sUKBUnG3/bzO8/\nrStJemDvPvbhv/+TwKgqcrldjTLp1YUmPqXipKrnecnS1U0lmviUipM2nVvR5cCK62V3bs4vs5xN\nNTxNfErF0WnXnICjXH07X6Gf/709M0ERpSZNfErF0c7NBTicZbu8geIga5evT1BEqUkTn1Jx1HtI\nL5xpZafPejM99B5S+f60qmFo4lMqjnoN6sHwPx6NO92NN9OLJ8PNoScdwsCRdau3p+pH5/EplQC/\nLVnDL3NX0rV3J7of3DXR4TQZuq+uUkmsy4EdKx3hjZcF/1vC5y9Nx+11c8oVw1Mu+WriUyrFfPL0\nFJ656TUCxQEcDmHaxK+4472b61zevjHTZ3xKpZBIJMILY98oKZdlWYZAcZCnb3g5sYHFmSY+pVJI\noDiIv8hf4fjmNdsSEE3iaOJTKoWkZ3lp06V1mWMOh3BQHAqkJhNNfEqlEBHhtonXkpGTTkZ2Ohk5\n6TRrncvfnros0aHFlQ5uKJVieg7szlvrnmXeFwtxeVz0P743aa7USgWp9W2VUgCkZ3o58rRBiQ4j\nYbSrq5RKOZr4lFIpRxOfUirlaOJTSqUcTXxKqZSjiU8plXI08SmlUo4mPqVUytHEp5RKOZr4lFIp\nRxOfUirlaOJTSqUcTXxKqZSjiU8plXI08SmlUo7W41MqyUUiET595gumvvolWc2zOP/W0+lz1AGJ\nDqtR08SnVJKbcMWzTH/z25Kd0RZ9tZS7PhjDIcP6Jjiyxku7ukolsV07Cpn6+tclSQ/sndJeuePt\nBEbV+GniUyqJ7dpeiMMpFY5v37gzAdE0HfVKfCLST0S+F5H5IjJHRFK3iL9SDaBt19ZkN88uc8zl\ncTH4dP2rVh/1bfE9CNxljOkH3B59rZSKEYfDwd0fjiG3ZQ7p2V486W56DerOJXedm+jQGrX6Dm4Y\nICf6cy6wvp7XU0qV06N/N95e/ywrflxFZrNMOvRol+iQGr36Jr7rgCki8jB26/GI+oeklCrPmeak\n58DuiQ6jyagx8YnIVKBtJW+NA44DrjfGvCci5wAvAMdXcZ3RwGiATp067XXASilVX2KM2fsPi+QD\nzYwxRkQEyDfG5NT0uQEDBpg5c+bs9X2VUqoyIjLXGDOgpvPqO7ixHhga/flY4Jd6Xk8ppRpcfZ/x\nXQZMEJE0wE+0K6uUUsmsXonPGPMNcEiMYlFKqbjQlRtKqZSjiU8plXI08SmlUk69prPs9U1FtgCr\n437jyrUEtiY6iFKSKZ5kigU0nppoPNDZGNOqppMSkviSiYjMqc28n3hJpniSKRbQeGqi8dSednWV\nUilHE59SKuVo4oNnEx1AOckUTzLFAhpPTTSeWkr5Z3xKqdSjLT6lVMrRxBclIteIyM8iskREEl5J\nWkRuEhEjIi0THMdDIvKTiCwUkQ9EpFmC4hgZ/f+zQkRuTUQMpWLpKCIzRGRZ9M/LtYmMJxqTU0R+\nFJFPkyCWZiIyKfrnZpmIHJ7omMrTxAeIyDHAqUAfY8yBwMMJjqcjMAz4PZFxRH0BHGSM6QMsB8bG\nOwARcQJPACcABwDni0giN5YNAzcaY/YHDgOuSnA8ANcCyxIcw24TgM+NMb2AviRPXCU08dmuBO43\nxgQAjDGbExzPP4Ex2KX9E8oY819jTDj68nugQwLCGASsMMasNMYEgbew/6FKCGPMBmPMvOjPu7D/\nYrdPVDwi0gE4CXg+UTGUiiUHOAq7KDHGmKAxJum2hNPEZ9sPGCIis0TkSxEZmKhARGQUsM4YsyBR\nMVTjT8B/EnDf9sCaUq/XksBEU5qIdAEOBmYlMIzHsP+htBIYw27dgC3AS9Gu9/MikpnooMqrbz2+\nRqOGEvppQB52t2Ug8I6IdDMNNORdQyy3AcMb4r57E48x5qPoOeOwu3gT4xlbVMWNZZOgNSwiWcB7\nwHXGmIIExXAysNkYM1dEjk5EDOWkAf2Ba4wxs0RkAnArMD6xYZWVMonPGFPpXiAAInIl8H400f0g\nIhb2OsMt8YxFRHoDXYEFdiV/OgDzRGSQMWZjQ8RSXTyl4roEOBk4rqH+MajBWqBjqdcdSPCOfiLi\nwk56E40x7ycwlCOBUSJyIuAFckTkdWPMHxIUz1pgrTFmdwt4EnbiSyra1bV9iF06HxHZD3CTgMXe\nxphFxpjWxpguxpgu2H+I+jdk0quJiIwEbgFGGWOKExTGbKCHiHQVETdwHvBxgmIhur/MC8AyY8yj\niYoDwBgz1hjTIfrn5TxgegKTHtE/q2tEpGf00HHA0kTFU5WUafHV4EXgRRFZDASBSxLUsklG/wY8\nwBfRVuj3xpgr4hmAMSYsIlcDUwAn8KIxZkk8YyjnSOAiYJGIzI8eu80YMzmBMSWTa4CJ0X+kVgKX\nJjieCnTlhlIq5WhXVymVcjTxKaVSjiY+pVTK0cSnlEo5mviUUilHE59SKuVo4lNKpRxNfEqplPP/\nm3OruYfqET0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.title(\"Two blobs\")\n",
    "X, labels = make_blobs(n_features = 2, centers = 2, cluster_std=1.25,  random_state = 123)\n",
    "plt.scatter(X[:, 0], X[:, 1], c = labels, s=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Max Margin Classifier\n",
    "Recall from the previous lesson that creating a support vector machine actually boils down to solving a convex optimization problem. You can use the the Python library \"cvxpy\" to do so, more information can be found [here](http://www.cvxpy.org/).\n",
    "\n",
    "You may have not used cvxpy before, so make sure it is installed using your terminal and the command `pip install cvxpy`.\n",
    "\n",
    "The four important commands to be used here are:\n",
    "\n",
    "- `cp.Variable()` where you either don't include antything between `()` or, if the variable is an array with multiple elements, the number of elements.\n",
    "- `cp.Minimize()` or `cp.Maximize`, with between the parentheses the element to be maximized.\n",
    "- `cp.Problem(objective, constraints)`, the objective is generally a stored minimization or maximization objective, the constraints are listed constraints. Constraints can be added by a \"+\" sign. \n",
    "- Next, you should store your `cp.Problem` in an object and use `object.solve()` to solve the optimization problem.\n",
    "\n",
    "To get more clarity, we strongly recommend to look at the example here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we're trying to solve this problem:\n",
    "\n",
    "$ w x^{(i)} + b \\geq 1$  if $y ^{(i)} = 1$\n",
    "\n",
    "$ w x^{(i)} + b \\leq -1$  if $y ^{(i)} = -1$\n",
    "\n",
    "And as an objective function we're maximizing $\\dfrac{2}{\\lVert w \\rVert}$. To make things easier, we'll minimizing $\\lVert w \\rVert$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $y^{(i)}$ is the class label here. Looking at our data the labels are stored in `labels`. Let's have a look at the labels by printing them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.06326521, -6.06306418],\n",
       "       [ 6.10902399, -5.27479172],\n",
       "       [ 3.42517616, -4.43475028],\n",
       "       [-7.22783202, -1.31979044],\n",
       "       [ 5.08871175, -4.4942579 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start to write down the optimization problem, let's split our data in the two classes. Name them `class_1` and `class_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1 = X[labels==0]\n",
    "class_2 = X[labels==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a wat to create a hyperplane (in this case, a line) that can maximize the difference between the two classes. \n",
    "- First, `import cvxpy as cp`\n",
    "- Next, define the variables. note that b and w are variables (what are the dimensions?)\n",
    "- Then, build the constraints. We have two constraints here\n",
    "- After that, use \"+\" to group the constraints togethes\n",
    "- The next step is to define the objective function\n",
    "- After that, define the problem using `cp.Problem`\n",
    "- Solve the problem using `.solve`\n",
    "- After that, print the problem status (however you defined the problem, and attach `.status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package              Version  \r\n",
      "-------------------- ---------\r\n",
      "absl-py              0.7.0    \r\n",
      "appnope              0.1.0    \r\n",
      "asn1crypto           0.24.0   \r\n",
      "astor                0.7.1    \r\n",
      "atomicwrites         1.3.0    \r\n",
      "attrs                18.2.0   \r\n",
      "backcall             0.1.0    \r\n",
      "bleach               1.5.0    \r\n",
      "certifi              2019.3.9 \r\n",
      "cffi                 1.11.5   \r\n",
      "chardet              3.0.4    \r\n",
      "convertdate          2.1.3    \r\n",
      "cryptography         2.3.1    \r\n",
      "cryptography-vectors 2.3.1    \r\n",
      "cvxpy                1.0.24   \r\n",
      "cycler               0.10.0   \r\n",
      "Cython               0.29.7   \r\n",
      "decorator            4.3.0    \r\n",
      "dill                 0.2.9    \r\n",
      "ecos                 2.0.5    \r\n",
      "entrypoints          0.3      \r\n",
      "ephem                3.7.6.0  \r\n",
      "fastcache            1.1.0    \r\n",
      "fbprophet            0.5      \r\n",
      "future               0.17.1   \r\n",
      "gast                 0.2.2    \r\n",
      "graphviz             0.10.1   \r\n",
      "grpcio               1.18.0   \r\n",
      "h5py                 2.9.0    \r\n",
      "holidays             0.9.10   \r\n",
      "html5lib             0.9999999\r\n",
      "idna                 2.7      \r\n",
      "ipykernel            5.1.0    \r\n",
      "ipynb                0.5.1    \r\n",
      "ipython              6.5.0    \r\n",
      "ipython-genutils     0.2.0    \r\n",
      "jedi                 0.12.1   \r\n",
      "Jinja2               2.10     \r\n",
      "jsonschema           2.6.0    \r\n",
      "jupyter-client       5.2.4    \r\n",
      "jupyter-core         4.4.0    \r\n",
      "Keras                2.2.1    \r\n",
      "Keras-Applications   1.0.4    \r\n",
      "Keras-Preprocessing  1.0.2    \r\n",
      "kiwisolver           1.0.1    \r\n",
      "lunardate            0.2.0    \r\n",
      "Markdown             3.0.1    \r\n",
      "MarkupSafe           1.1.0    \r\n",
      "matplotlib           3.0.3    \r\n",
      "mistune              0.8.4    \r\n",
      "mkl-fft              1.0.6    \r\n",
      "mkl-random           1.0.1    \r\n",
      "more-itertools       6.0.0    \r\n",
      "multiprocess         0.70.7   \r\n",
      "nb-conda             2.2.1    \r\n",
      "nb-conda-kernels     2.2.0    \r\n",
      "nbconvert            5.3.1    \r\n",
      "nbformat             4.4.0    \r\n",
      "networkx             2.3      \r\n",
      "nose                 1.3.7    \r\n",
      "notebook             5.7.4    \r\n",
      "numpy                1.16.3   \r\n",
      "obscure              1.0.1    \r\n",
      "osqp                 0.4.1    \r\n",
      "pandas               0.23.4   \r\n",
      "pandocfilters        1.4.2    \r\n",
      "parso                0.3.1    \r\n",
      "patsy                0.5.1    \r\n",
      "pexpect              4.6.0    \r\n",
      "pickleshare          0.7.4    \r\n",
      "pip                  19.1.1   \r\n",
      "plotly               3.1.0    \r\n",
      "pluggy               0.8.1    \r\n",
      "prometheus-client    0.5.0    \r\n",
      "prompt-toolkit       1.0.15   \r\n",
      "protobuf             3.6.1    \r\n",
      "ptyprocess           0.6.0    \r\n",
      "py                   1.7.0    \r\n",
      "pycparser            2.18     \r\n",
      "Pygments             2.2.0    \r\n",
      "pyOpenSSL            18.0.0   \r\n",
      "pyparsing            2.3.1    \r\n",
      "PySocks              1.6.8    \r\n",
      "pystan               2.18.0.0 \r\n",
      "pytest               3.7.0    \r\n",
      "python-dateutil      2.7.5    \r\n",
      "pytz                 2018.5   \r\n",
      "PyYAML               3.13     \r\n",
      "pyzmq                17.1.2   \r\n",
      "requests             2.19.1   \r\n",
      "retrying             1.3.3    \r\n",
      "scikit-learn         0.20.1   \r\n",
      "scipy                1.1.0    \r\n",
      "scs                  2.0.2    \r\n",
      "seaborn              0.9.0    \r\n",
      "Send2Trash           1.5.0    \r\n",
      "setuptools           40.0.0   \r\n",
      "simplegeneric        0.8.1    \r\n",
      "six                  1.11.0   \r\n",
      "statsmodels          0.9.0    \r\n",
      "tensorboard          1.6.0    \r\n",
      "tensorflow           1.6.0    \r\n",
      "termcolor            1.1.0    \r\n",
      "terminado            0.8.1    \r\n",
      "testpath             0.4.2    \r\n",
      "tornado              5.1.1    \r\n",
      "traitlets            4.3.2    \r\n",
      "urllib3              1.23     \r\n",
      "wcwidth              0.1.7    \r\n",
      "webencodings         0.5.1    \r\n",
      "Werkzeug             0.14.1   \r\n",
      "wheel                0.31.1   \r\n",
      "xlrd                 1.1.0    \r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvxpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fe5ab8d28168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcvxpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cvxpy'"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the variables\n",
    "\n",
    "\n",
    "# Define the constraints\n",
    "\n",
    "\n",
    "# Sum the constraints\n",
    "\n",
    "\n",
    "# Define the objective. Hint: use cp.norm\n",
    "\n",
    "\n",
    "# Add objective and constraint in the problem\n",
    "\n",
    "\n",
    "# Solve the problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we provide you with a helper function to plot your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a helper function for plotting the results, the decision plane, and the supporting planes\n",
    "\n",
    "def plotBoundaries(x, y, w, b):\n",
    "    # Takes in a set of datapoints x and y for two clusters,\n",
    "    d1_min = np.min([x[:,0],y[:,0]])\n",
    "    d1_max = np.max([x[:,0],y[:,0]])\n",
    "    # Line form: (-a[0] * x - b ) / a[1]\n",
    "    d2_at_mind1 = (-w[0]*d1_min - b ) / w[1]\n",
    "    d2_at_maxd1 = (-w[0]*d1_max - b ) / w[1]\n",
    "    sup_up_at_mind1 = (-w[0]*d1_min - b + 1 ) / w[1]\n",
    "    sup_up_at_maxd1 = (-w[0]*d1_max - b + 1 ) / w[1]\n",
    "    sup_dn_at_mind1 = (-w[0]*d1_min - b - 1 ) / w[1]\n",
    "    sup_dn_at_maxd1 = (-w[0]*d1_max - b - 1 ) / w[1]\n",
    "\n",
    "    # Plot the clusters!\n",
    "    plt.scatter(x[:,0],x[:,1],color='purple')\n",
    "    plt.scatter(y[:,0],y[:,1],color='yellow')\n",
    "    plt.plot([d1_min,d1_max],[d2_at_mind1 ,d2_at_maxd1],color='black')\n",
    "    plt.plot([d1_min,d1_max],[sup_up_at_mind1,sup_up_at_maxd1],'-.',color='blue')\n",
    "    plt.plot([d1_min,d1_max],[sup_dn_at_mind1,sup_dn_at_maxd1],'-.',color='blue')\n",
    "    plt.ylim([np.floor(np.min([x[:,1],y[:,1]])),np.ceil(np.max([x[:,1],y[:,1]]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the helper function to plot your result. To get the values of `w` and `b`. use the two variables with `.value`. The two first arguments should be the two classes, `class_1` and `class_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another problem by running the code below. It's clear that now, the two classes are not perfectly linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.title(\"Two blobs\")\n",
    "X, labels = make_blobs(n_features = 2, centers = 2, cluster_std=3,  random_state = 123)\n",
    "plt.scatter(X[:, 0], X[:, 1], c = labels, s=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy your optimization code from the Max Margin Classifier and look at the problem status. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the optimization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain what's happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem status is \"infeasible\": the problem is not linearly separable, in other words, we cannot draw one straight line that separates the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Soft Margin Classifier\n",
    "\n",
    "To solve this problem, you'll need to \"relax\" your constraints and allow for items that are not correctly classified. This is where the Soft Margin Classifier comes in! As a refresher, this is the formulation for the Soft Margin Classifier:\n",
    "\n",
    "$$ b + w_Tx^{(i)} \\geq 1-\\xi^{(i)}  \\text{     if     } y ^{(i)} = 1$$\n",
    "\n",
    "$$ b + w_Tx^{(i)} \\leq -1+\\xi^{(i)}  \\text{     if     } y ^{(i)} = -1$$\n",
    "\n",
    "\n",
    "The objective function is \n",
    "\n",
    " $$\\dfrac{1}{2}\\lVert w \\rVert^2+ C(\\sum_i \\xi^{(i)})$$\n",
    " \n",
    " We created the new data set again below. Let's use the code for the SVM optimization again, but adjust for the slack parameters $\\xi$ (ksi or xi).\n",
    " \n",
    "Some important things to note:\n",
    "- Every $\\xi$ needs to be positive, that should be added as constraints\n",
    "- Your objective needs to be changed as well\n",
    "- Allow for a \"hyperparameter\" C which you set to 1 at first and you can change accordingly. Describe how your result changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.title(\"Two blobs\")\n",
    "X, labels = make_blobs(n_features = 2, centers = 2, cluster_std=3,  random_state = 123)\n",
    "plt.scatter(X[:, 0], X[:, 1], c = labels, s=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassign the class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the variables\n",
    "\n",
    "\n",
    "# Define the constraints\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sum the constraints\n",
    "\n",
    "# Define the objective. Hint: use cp.norm. Add in a C hyperparameter and assume 1 at first\n",
    "\n",
    "\n",
    "# Add objective and constraint in the problem\n",
    "\n",
    "\n",
    "# Solve the problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your result again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go ahead and experiment with the hyperparameter C (making it both larger and smaller than 1). What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now understand the rationale behind support vector machines. Wouldn't it be great to have a library that did this for you? Well, you're lucky: scikit-learn has an SVM-module which automizes all of this. In the next lab, you'll learn how to use this scikit-learn module!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
